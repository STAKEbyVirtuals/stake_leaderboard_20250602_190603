# === STAKE ë¦¬ë”ë³´ë“œ í†µí•© ì‹œìŠ¤í…œ (Apps Script Web App ì—°ë™) ===
import requests
import pandas as pd
import json
import logging
import time
import schedule
from datetime import datetime, timezone
from collections import defaultdict
import traceback
import os

# === ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ í•¨ìˆ˜ë“¤ ===
def load_checkpoint():
    """ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ë¡œë“œ"""
    checkpoint_file = 'checkpoint.json'
    try:
        with open(checkpoint_file, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        # ì´ˆê¸° ì²´í¬í¬ì¸íŠ¸ ìƒì„±
        initial_checkpoint = {
            "last_full_scan": {
                "block": GENESIS_BLOCK,
                "timestamp": None,
                "total_users": 0
            },
            "last_incremental": {
                "block": GENESIS_BLOCK,
                "timestamp": None
            },
            "genesis_scan_completed": False
        }
        save_checkpoint(initial_checkpoint)
        return initial_checkpoint

def save_checkpoint(checkpoint_data):
    """ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì €ì¥"""
    checkpoint_file = 'checkpoint.json'
    with open(checkpoint_file, 'w') as f:
        json.dump(checkpoint_data, f, indent=2)
    logger.info(f"âœ… ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('stake_leaderboard.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# === ì„¤ì • ë³€ê²½: Sheet.best â†’ Apps Script Web App ===
SAFE_MODE = os.environ.get('SAFE_MODE', 'false').lower() == 'true'
UPDATE_RANGE = os.environ.get('UPDATE_RANGE', 'A:U')

if SAFE_MODE:
    logger.info("ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œ í™œì„±í™”: ê¸°ì¡´ 21ê°œ ì»¬ëŸ¼ë§Œ ì—…ë°ì´íŠ¸")
    logger.info(f"ğŸ“Š ì—…ë°ì´íŠ¸ ë²”ìœ„: {UPDATE_RANGE}")
else:
    logger.info("âš ï¸ ì¼ë°˜ ëª¨ë“œ: ì „ì²´ ë²”ìœ„ ì—…ë°ì´íŠ¸")

# === ì„¤ì • ===
RPC_URL = "https://mainnet.base.org"
STAKING_ADDRESS = "0xBa13ae24684bee910820Be1Fcf52067332F8412f"
TOKEN_ADDRESS = "0xA9C8bDDcb113068713193D030abB86C7e8D1F5bB"
STAKE_METHOD_ID = "0xa694fc3a"
UNSTAKE_METHOD_ID = "0xf48355b9"
GENESIS_BLOCK = 30732159

# ğŸš€ Apps Script Web App URL (GitHub Actions í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
APPS_SCRIPT_WEB_APP_URL = os.environ.get('APPS_SCRIPT_WEB_APP_URL')

if not APPS_SCRIPT_WEB_APP_URL:
    # ë¡œì»¬ ê°œë°œ ì‹œ ê¸°ë³¸ê°’
    APPS_SCRIPT_WEB_APP_URL = ''
    logger.warning("âš ï¸ APPS_SCRIPT_WEB_APP_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
else:
    logger.info(f"âœ… Apps Script Web App URL ì„¤ì • ì™„ë£Œ: {APPS_SCRIPT_WEB_APP_URL[:50]}...")

# í˜ì´ì¦ˆ ì„¤ì •
CURRENT_PHASE = 1
TOTAL_PHASES = 6
TOTAL_SUPPLY = 1_000_000_000
AIRDROP_PERCENT = 0.25
PHASE_REWARD = (TOTAL_SUPPLY * AIRDROP_PERCENT) / TOTAL_PHASES

# ì „ì²´ ë°ì´í„° ì €ì¥ì†Œ
staking_data = defaultdict(lambda: {
    'total_staked': 0,
    'stake_count': 0,
    'unstake_count': 0,
    'unstake_attempts': [],
    'is_active': True,
    'first_stake_time': None,
    'last_action_time': None,
    'stake_transactions': [],
    'unstake_transactions': []
})

# === ì•ˆì „ ëª¨ë“œìš© ì»¬ëŸ¼ ì •ì˜ ===
SAFE_MODE_COLUMNS = [
    'address', 'rank', 'grade', 'grade_emoji', 'percentile',
    'total_staked', 'time_score', 'holding_days', 'stake_count', 'unstake_count',
    'is_active', 'current_phase', 'phase_score', 'total_score_all_phases',
    'airdrop_share_phase', 'airdrop_share_total', 'first_stake_time', 'last_action_time',
    'rank_change_24h', 'score_change_24h', 'phase_rank_history'
]

def apply_safe_mode_filter(data):
    """ì•ˆì „ ëª¨ë“œ: ê¸°ì¡´ 21ê°œ ì»¬ëŸ¼ë§Œ í•„í„°ë§"""
    if not SAFE_MODE:
        return data
    
    logger.info("ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œ í•„í„° ì ìš©: 21ê°œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ")
    
    filtered_data = []
    for item in data:
        filtered_item = {}
        for column in SAFE_MODE_COLUMNS:
            filtered_item[column] = item.get(column, '')
        filtered_data.append(filtered_item)
    
    logger.info(f"âœ… ì•ˆì „ ëª¨ë“œ í•„í„°ë§ ì™„ë£Œ: {len(filtered_data)}ê°œ í•­ëª©, {len(SAFE_MODE_COLUMNS)}ê°œ ì»¬ëŸ¼")
    return filtered_data

def rpc_call(method, params):
    """RPC í˜¸ì¶œ with ì—ëŸ¬ í•¸ë“¤ë§"""
    try:
        response = requests.post(RPC_URL, json={
            "jsonrpc": "2.0",
            "method": method,
            "params": params,
            "id": 1
        }, timeout=30)
        
        result = response.json()
        if 'error' in result:
            logger.error(f"RPC Error: {result['error']}")
            return None
        return result
    except Exception as e:
        logger.error(f"RPC í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return None

def get_latest_block():
    """ìµœì‹  ë¸”ë¡ ë²ˆí˜¸ ì¡°íšŒ"""
    result = rpc_call("eth_blockNumber", [])
    if result and 'result' in result:
        return int(result['result'], 16)
    return 0

def decode_amount(input_data):
    """ìŠ¤í…Œì´í‚¹ ìˆ˜ëŸ‰ ë””ì½”ë“œ"""
    try:
        if len(input_data) < 74:
            return 0
        amount_hex = input_data[10:74]
        return int(amount_hex, 16) / (10**18)
    except:
        return 0

def safe_scan_chunk(start_block, end_block, max_retries=3):
    """ì•ˆì „í•œ ì²­í¬ ìŠ¤ìº” with ì¬ì‹œë„"""
    chunk_size = end_block - start_block + 1
    
    # 1500ë¸”ë¡ ì´ˆê³¼í•˜ë©´ ë‚˜ëˆ„ê¸°
    if chunk_size > 1500:
        mid = start_block + 1499
        logs1 = safe_scan_chunk(start_block, mid, max_retries)
        logs2 = safe_scan_chunk(mid + 1, end_block, max_retries)
        return logs1 + logs2
    
    # ì¬ì‹œë„ ë¡œì§
    for attempt in range(max_retries):
        try:
            result = rpc_call("eth_getLogs", [{
                "fromBlock": hex(start_block),
                "toBlock": hex(end_block),
                "address": STAKING_ADDRESS
            }])
            
            if result and 'error' in result:
                if chunk_size > 1000:
                    mid = start_block + 999
                    logs1 = safe_scan_chunk(start_block, mid, max_retries)
                    logs2 = safe_scan_chunk(mid + 1, end_block, max_retries)
                    return logs1 + logs2
                else:
                    logger.warning(f"ì²­í¬ ìŠ¤ìº” ì‹¤íŒ¨: {result['error']}")
                    return []
            
            elif result and 'result' in result:
                return result['result']
            else:
                logger.warning(f"ë¹ˆ ê²°ê³¼: ë¸”ë¡ {start_block}-{end_block}")
                return []
                
        except Exception as e:
            logger.error(f"ì²­í¬ ìŠ¤ìº” ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
            
    return []

def calculate_grade_percentile(data, genesis_deadline, all_active_wallets):
    """ë“±ê¸‰ ê³„ì‚° (í¼ì„¼íƒ€ì¼ ê¸°ì¤€)"""
    # Genesis: ì œë„¤ì‹œìŠ¤ ë¸”ë¡ ì´í›„ 1ì¼ ë‚´ ìŠ¤í…Œì´í‚¹ + ì–¸ìŠ¤í…Œì´í‚¹ ì‹œë„ ì—†ìŒ
    if (data['first_stake_time'] and 
        data['first_stake_time'] <= genesis_deadline and 
        data['is_active'] and 
        data['unstake_count'] == 0):
        return "Genesis OG", 0.0
    
    # ì–¸ìŠ¤í…Œì´í‚¹ ì‹œë„í•œ ê²½ìš°
    if not data['is_active']:
        return "Jeeted", 100.0
    
    # í™œì„± ì§€ê°‘ë“¤ì˜ íƒ€ì„ìŠ¤ì½”ì–´ ê¸°ì¤€ í¼ì„¼íƒ€ì¼ ê³„ì‚°
    current_time = int(datetime.now(timezone.utc).timestamp())
    holding_days = (current_time - data['first_stake_time']) / 86400 if data['first_stake_time'] else 0
    time_score = data['total_staked'] * holding_days
    
    # ëª¨ë“  í™œì„± ì§€ê°‘ì˜ íƒ€ì„ìŠ¤ì½”ì–´ ê³„ì‚°
    all_scores = []
    for _, wallet_data in all_active_wallets:
        if wallet_data['first_stake_time']:
            w_holding_days = (current_time - wallet_data['first_stake_time']) / 86400
            w_time_score = wallet_data['total_staked'] * w_holding_days
            all_scores.append(w_time_score)
    
    if not all_scores:
        return "Sizzlin' Noob", 100.0
    
    all_scores.sort(reverse=True)
    rank = len([s for s in all_scores if s > time_score]) + 1
    percentile = (rank / len(all_scores)) * 100
    
    # í¼ì„¼íƒ€ì¼ ê¸°ì¤€ ë“±ê¸‰
    if percentile <= 0.5:
        return "Smoke Flexer", percentile
    elif percentile <= 2:
        return "Steak Wizard", percentile
    elif percentile <= 5:
        return "Grilluminati", percentile
    elif percentile <= 15:
        return "Flame Juggler", percentile
    elif percentile <= 40:
        return "Flipstarter", percentile
    else:
        return "Sizzlin' Noob", percentile

def get_grade_emoji(grade):
    """ë“±ê¸‰ë³„ ì´ëª¨ì§€"""
    grade_emojis = {
        "Genesis OG": "ğŸŒŒ",
        "Smoke Flexer": "ğŸ”¥",
        "Steak Wizard": "ğŸ­",
        "Grilluminati": "ğŸ‘ï¸",
        "Flame Juggler": "ğŸ”¥",
        "Flipstarter": "ğŸ¥©",
        "Sizzlin' Noob": "ğŸ”°",
        "Jeeted": "ğŸ’€"
    }
    return grade_emojis.get(grade, "â“")

def extract_all_stake_data():
    """ì™„ì „í•œ STAKE ë°ì´í„° ì¶”ì¶œ"""
    logger.info("ğŸš€ ì „ì²´ STAKE ë°ì´í„° ì¶”ì¶œ ì‹œì‘...")
    
    try:
        latest_block = get_latest_block()
        if not latest_block:
            raise Exception("ìµœì‹  ë¸”ë¡ ì¡°íšŒ ì‹¤íŒ¨")
        
        total_blocks = latest_block - GENESIS_BLOCK
        logger.info(f"ğŸ“Š ìŠ¤ìº” ë²”ìœ„: {GENESIS_BLOCK:,} â†’ {latest_block:,} ({total_blocks:,}ë¸”ë¡)")
        
        # ì´ˆê¸°í™”
        staking_data.clear()
        
        total_stake_txs = 0
        total_unstake_txs = 0
        processed = 0
        
        current_block = GENESIS_BLOCK
        chunk_num = 1
        
        while current_block <= latest_block:
            chunk_end = min(current_block + 1499, latest_block)
            chunk_size = chunk_end - current_block + 1
            
            progress = processed / total_blocks * 100
            logger.info(f"ğŸ”„ {progress:.1f}% | ì²­í¬#{chunk_num} | ë¸”ë¡ {current_block:,}â†’{chunk_end:,}")
            
            logs = safe_scan_chunk(current_block, chunk_end)
            
            if not logs:
                current_block = chunk_end + 1
                processed += chunk_size
                chunk_num += 1
                continue
            
            # íŠ¸ëœì­ì…˜ ì²˜ë¦¬
            tx_hashes = list(set(log['transactionHash'] for log in logs))
            
            for tx_hash in tx_hashes:
                try:
                    tx_result = rpc_call("eth_getTransactionByHash", [tx_hash])
                    
                    if not tx_result or 'result' not in tx_result or not tx_result['result']:
                        continue
                    
                    tx = tx_result['result']
                    input_data = tx.get('input', '0x')
                    
                    if len(input_data) >= 10:
                        method_id = input_data[:10]
                        from_addr = tx['from'].lower()
                        block_num = int(tx['blockNumber'], 16)
                        
                        # ë¸”ë¡ íƒ€ì„ìŠ¤íƒ¬í”„
                        block_result = rpc_call("eth_getBlockByNumber", [tx['blockNumber'], False])
                        timestamp = 0
                        if block_result and 'result' in block_result and block_result['result']:
                            timestamp = int(block_result['result']['timestamp'], 16)
                        
                        if method_id == STAKE_METHOD_ID:
                            # ìŠ¤í…Œì´í‚¹ íŠ¸ëœì­ì…˜
                            amount = decode_amount(input_data)
                            
                            staking_data[from_addr]['total_staked'] += amount
                            staking_data[from_addr]['stake_count'] += 1
                            staking_data[from_addr]['is_active'] = True
                            
                            if not staking_data[from_addr]['first_stake_time']:
                                staking_data[from_addr]['first_stake_time'] = timestamp
                            
                            staking_data[from_addr]['last_action_time'] = timestamp
                            
                            staking_data[from_addr]['stake_transactions'].append({
                                'amount': amount,
                                'block': block_num,
                                'timestamp': timestamp,
                                'hash': tx_hash
                            })
                            
                            total_stake_txs += 1
                        
                        elif method_id == UNSTAKE_METHOD_ID:
                            # ì–¸ìŠ¤í…Œì´í‚¹ ì‹œë„
                            staking_data[from_addr]['unstake_count'] += 1
                            staking_data[from_addr]['is_active'] = False
                            staking_data[from_addr]['last_action_time'] = timestamp
                            
                            staking_data[from_addr]['unstake_attempts'].append({
                                'block': block_num,
                                'timestamp': timestamp,
                                'hash': tx_hash
                            })
                            
                            total_unstake_txs += 1
                
                except Exception as e:
                    continue
                    
                time.sleep(0.005)
            
            current_block = chunk_end + 1
            processed += chunk_size
            chunk_num += 1
            time.sleep(0.1)
        
        logger.info(f"ğŸ‰ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ!")
        logger.info(f"   ì´ Stake íŠ¸ëœì­ì…˜: {total_stake_txs:,}ê°œ")
        logger.info(f"   ì´ Unstake ì‹œë„: {total_unstake_txs:,}ê°œ")
        logger.info(f"   ì´ ì§€ê°‘ ìˆ˜: {len(staking_data):,}ê°œ")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        logger.error(traceback.format_exc())
        return False
    
def extract_incremental_stake_data():
    """ì¦ë¶„ ëª¨ë“œ: ìµœê·¼ ë³€ê²½ì‚¬í•­ë§Œ ì¶”ì¶œ"""
    logger.info("ğŸš€ ì¦ë¶„ STAKE ë°ì´í„° ì¶”ì¶œ ì‹œì‘...")
    
    try:
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        checkpoint = load_checkpoint()
        latest_block = get_latest_block()
        
        if not latest_block:
            raise Exception("ìµœì‹  ë¸”ë¡ ì¡°íšŒ ì‹¤íŒ¨")
        
        # ğŸ†• ì´ˆê¸° ìŠ¤ìº”ì´ ì—†ìœ¼ë©´ ìµœê·¼ ë¸”ë¡ë§Œ ì²˜ë¦¬
        if not checkpoint.get('genesis_scan_completed', False):
            logger.warning("âš ï¸ ì´ˆê¸° ì „ì²´ ìŠ¤ìº”ì´ ì•„ì§ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            logger.info("ğŸ“Š ìµœê·¼ 10,000ë¸”ë¡ë§Œ ìŠ¤ìº”í•©ë‹ˆë‹¤.")
            
            # ìµœê·¼ 10,000ë¸”ë¡ë¶€í„° ì‹œì‘
            start_block = max(GENESIS_BLOCK, latest_block - 10000)
            
            # ë°±ì—… ë°ì´í„° ë¡œë“œ ì‹œë„
            try:
                import glob
                backup_files = glob.glob('backup/stake_leaderboard_*.json')
                if backup_files:
                    latest_backup = max(backup_files)
                    logger.info(f"ğŸ“‚ ë°±ì—… íŒŒì¼ ë°œê²¬: {latest_backup}")
                    with open(latest_backup, 'r') as f:
                        backup_data = json.load(f)
                        # staking_data ë³µì›
                        for item in backup_data:
                            addr = item['address'].lower()
                            staking_data[addr] = {
                                'total_staked': item.get('total_staked', 0),
                                'stake_count': item.get('stake_count', 0),
                                'unstake_count': item.get('unstake_count', 0),
                                'unstake_attempts': [],
                                'is_active': item.get('is_active', True),
                                'first_stake_time': item.get('first_stake_time'),
                                'last_action_time': item.get('last_action_time'),
                                'stake_transactions': [],
                                'unstake_transactions': []
                            }
                        logger.info(f"âœ… {len(staking_data)}ê°œ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
                else:
                    # public/leaderboard.json ì‹œë„
                    if os.path.exists('../public/leaderboard.json'):
                        with open('../public/leaderboard.json', 'r') as f:
                            public_data = json.load(f)
                            if 'leaderboard' in public_data:
                                for item in public_data['leaderboard']:
                                    addr = item['address'].lower()
                                    staking_data[addr] = {
                                        'total_staked': item.get('total_staked', 0),
                                        'stake_count': item.get('stake_count', 0),
                                        'unstake_count': item.get('unstake_count', 0),
                                        'unstake_attempts': [],
                                        'is_active': item.get('is_active', True),
                                        'first_stake_time': item.get('first_stake_time'),
                                        'last_action_time': item.get('last_action_time'),
                                        'stake_transactions': [],
                                        'unstake_transactions': []
                                    }
                                logger.info(f"âœ… publicì—ì„œ {len(staking_data)}ê°œ ë°ì´í„° ë¡œë“œ")
            except Exception as e:
                logger.warning(f"âš ï¸ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
                logger.info("ğŸ†• ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
        else:
            # ì •ìƒì ì¸ ì¦ë¶„ ì²˜ë¦¬
            start_block = checkpoint['last_incremental']['block'] + 1
            
            # ë„ˆë¬´ ë§ì€ ë¸”ë¡ ë°©ì§€ (ìµœëŒ€ 10,000ë¸”ë¡)
            if latest_block - start_block > 10000:
                start_block = latest_block - 10000
                logger.warning(f"âš ï¸ ë¸”ë¡ ë²”ìœ„ ì œí•œ: ìµœê·¼ 10,000ë¸”ë¡ë§Œ ìŠ¤ìº”")
        
        if start_block > latest_block:
            logger.info("âœ… ìƒˆë¡œìš´ ë¸”ë¡ ì—†ìŒ")
            return True
        
        total_blocks = latest_block - start_block
        logger.info(f"ğŸ“Š ì¦ë¶„ ìŠ¤ìº” ë²”ìœ„: {start_block:,} â†’ {latest_block:,} ({total_blocks:,}ë¸”ë¡)")
        
        # ê¸°ì¡´ ë°ì´í„° ìœ ì§€ (ì „ì²´ ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ)
        # staking_dataëŠ” ì „ì—­ ë³€ìˆ˜ì´ë¯€ë¡œ ê¸°ì¡´ ë°ì´í„° ìœ ì§€ë¨
        
        total_stake_txs = 0
        total_unstake_txs = 0
        processed = 0
        
        current_block = start_block
        chunk_num = 1
        
        while current_block <= latest_block:
            chunk_end = min(current_block + 1499, latest_block)
            chunk_size = chunk_end - current_block + 1
            
            progress = processed / total_blocks * 100
            logger.info(f"ğŸ”„ ì¦ë¶„ {progress:.1f}% | ì²­í¬#{chunk_num} | ë¸”ë¡ {current_block:,}â†’{chunk_end:,}")
            
            logs = safe_scan_chunk(current_block, chunk_end)
            
            if not logs:
                current_block = chunk_end + 1
                processed += chunk_size
                chunk_num += 1
                continue
            
            # íŠ¸ëœì­ì…˜ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©)
            tx_hashes = list(set(log['transactionHash'] for log in logs))
            
            for tx_hash in tx_hashes:
                try:
                    tx_result = rpc_call("eth_getTransactionByHash", [tx_hash])
                    
                    if not tx_result or 'result' not in tx_result or not tx_result['result']:
                        continue
                    
                    tx = tx_result['result']
                    input_data = tx.get('input', '0x')
                    
                    if len(input_data) >= 10:
                        method_id = input_data[:10]
                        from_addr = tx['from'].lower()
                        block_num = int(tx['blockNumber'], 16)
                        
                        # ë¸”ë¡ íƒ€ì„ìŠ¤íƒ¬í”„
                        block_result = rpc_call("eth_getBlockByNumber", [tx['blockNumber'], False])
                        timestamp = 0
                        if block_result and 'result' in block_result and block_result['result']:
                            timestamp = int(block_result['result']['timestamp'], 16)
                        
                        if method_id == STAKE_METHOD_ID:
                            # ìŠ¤í…Œì´í‚¹ íŠ¸ëœì­ì…˜
                            amount = decode_amount(input_data)
                            
                            staking_data[from_addr]['total_staked'] += amount
                            staking_data[from_addr]['stake_count'] += 1
                            staking_data[from_addr]['is_active'] = True
                            
                            if not staking_data[from_addr]['first_stake_time']:
                                staking_data[from_addr]['first_stake_time'] = timestamp
                            
                            staking_data[from_addr]['last_action_time'] = timestamp
                            
                            staking_data[from_addr]['stake_transactions'].append({
                                'amount': amount,
                                'block': block_num,
                                'timestamp': timestamp,
                                'hash': tx_hash
                            })
                            
                            total_stake_txs += 1
                            logger.info(f"âœ… ìƒˆ ìŠ¤í…Œì´í‚¹: {from_addr[:8]}... +{amount:.4f}")
                        
                        elif method_id == UNSTAKE_METHOD_ID:
                            # ì–¸ìŠ¤í…Œì´í‚¹ ì‹œë„
                            staking_data[from_addr]['unstake_count'] += 1
                            staking_data[from_addr]['is_active'] = False
                            staking_data[from_addr]['last_action_time'] = timestamp
                            
                            staking_data[from_addr]['unstake_attempts'].append({
                                'block': block_num,
                                'timestamp': timestamp,
                                'hash': tx_hash
                            })
                            
                            total_unstake_txs += 1
                            logger.info(f"âŒ ì–¸ìŠ¤í…Œì´í‚¹: {from_addr[:8]}...")
                
                except Exception as e:
                    continue
                    
                time.sleep(0.005)
            
            current_block = chunk_end + 1
            processed += chunk_size
            chunk_num += 1
            time.sleep(0.1)
        
        # ì²´í¬í¬ì¸íŠ¸ ì—…ë°ì´íŠ¸
        checkpoint['last_incremental'] = {
            'block': latest_block,
            'timestamp': datetime.now(timezone.utc).isoformat()
        }
        save_checkpoint(checkpoint)
        
        logger.info(f"ğŸ‰ ì¦ë¶„ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ!")
        logger.info(f"   ìƒˆ Stake íŠ¸ëœì­ì…˜: {total_stake_txs:,}ê°œ")
        logger.info(f"   ìƒˆ Unstake ì‹œë„: {total_unstake_txs:,}ê°œ")
        logger.info(f"   ì˜í–¥ë°›ì€ ì§€ê°‘: {total_stake_txs + total_unstake_txs}ê°œ")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ì¦ë¶„ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        logger.error(traceback.format_exc())
        return False    

def process_leaderboard_data():
    """ë¦¬ë”ë³´ë“œ ë°ì´í„° ì²˜ë¦¬ ë° ìƒì„± (ì•ˆì „ ëª¨ë“œ ì§€ì›)"""
    logger.info("ğŸ“Š ë¦¬ë”ë³´ë“œ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘...")
    
    try:
        # ì œë„¤ì‹œìŠ¤ ë¸”ë¡ íƒ€ì„ìŠ¤íƒ¬í”„ ê³„ì‚°
        block_result = rpc_call("eth_getBlockByNumber", [hex(GENESIS_BLOCK), False])
        genesis_timestamp = 0
        if block_result and 'result' in block_result and block_result['result']:
            genesis_timestamp = int(block_result['result']['timestamp'], 16)
        
        genesis_deadline = genesis_timestamp + 86400  # 1ì¼ í›„
        
        # í™œì„± ì§€ê°‘ë§Œ ì¶”ì¶œ
        all_wallets = [(addr, data) for addr, data in staking_data.items() if data['total_staked'] > 0]
        active_wallets = [(addr, data) for addr, data in all_wallets if data['is_active']]
        
        # íƒ€ì„ìŠ¤ì½”ì–´ ê¸°ì¤€ ì •ë ¬
        sorted_wallets = sorted(all_wallets, key=lambda x: (
            x[1]['total_staked'] * ((int(datetime.now(timezone.utc).timestamp()) - x[1]['first_stake_time']) / 86400)
            if x[1]['first_stake_time'] else 0
        ), reverse=True)
        
        leaderboard_data = []
        total_time_score = 0
        
        # ì „ì²´ íƒ€ì„ìŠ¤ì½”ì–´ ê³„ì‚° (ì—ì–´ë“œë ë¹„ìœ¨ ê³„ì‚°ìš©)
        current_time = int(datetime.now(timezone.utc).timestamp())
        for _, data in active_wallets:
            if data['first_stake_time']:
                holding_days = (current_time - data['first_stake_time']) / 86400
                total_time_score += data['total_staked'] * holding_days
        
        for rank, (address, data) in enumerate(sorted_wallets, 1):
            # ë“±ê¸‰ ë° í¼ì„¼íƒ€ì¼ ê³„ì‚°
            grade, percentile = calculate_grade_percentile(data, genesis_deadline, active_wallets)
            
            # íƒ€ì„ìŠ¤ì½”ì–´ ê³„ì‚°
            holding_days = 0
            time_score = 0
            if data['first_stake_time']:
                holding_days = (current_time - data['first_stake_time']) / 86400
                time_score = data['total_staked'] * holding_days
            
            # ì—ì–´ë“œë í• ë‹¹ ë¹„ìœ¨ ê³„ì‚°
            airdrop_share_phase = 0
            airdrop_share_total = 0
            if data['is_active'] and total_time_score > 0:
                airdrop_share_phase = (time_score / total_time_score) * 100
                airdrop_share_total = airdrop_share_phase * TOTAL_PHASES
            
            # 24ì‹œê°„ ë³€ë™ (ì„ì‹œë¡œ 0 ì„¤ì •, í–¥í›„ ì´ì „ ë°ì´í„°ì™€ ë¹„êµ)
            rank_change_24h = 0
            score_change_24h = 0
            
            # ê¸°ë³¸ 21ê°œ ì»¬ëŸ¼ ë°ì´í„°
            item_data = {
                'address': address,
                'rank': rank,
                'grade': grade,
                'grade_emoji': get_grade_emoji(grade),
                'percentile': round(percentile, 2),
                'total_staked': round(data['total_staked'], 4),
                'time_score': round(time_score, 2),
                'holding_days': round(holding_days, 1),
                'stake_count': data['stake_count'],
                'unstake_count': data['unstake_count'],
                'is_active': data['is_active'],
                'current_phase': CURRENT_PHASE,
                'phase_score': round(time_score, 2),
                'total_score_all_phases': round(time_score, 2),
                'airdrop_share_phase': round(airdrop_share_phase, 6),
                'airdrop_share_total': round(airdrop_share_total, 6),
                'first_stake_time': data['first_stake_time'],
                'last_action_time': data['last_action_time'],
                'rank_change_24h': rank_change_24h,
                'score_change_24h': score_change_24h,
                'phase_rank_history': f"P1:{rank}"
            }
            
            leaderboard_data.append(item_data)
        
        # ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œ í•„í„° ì ìš©
        if SAFE_MODE:
            leaderboard_data = apply_safe_mode_filter(leaderboard_data)
            logger.info("ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œ: ì‹ ê·œ 18ê°œ ì»¬ëŸ¼ì€ Apps Scriptì—ì„œ ìë™ ìƒì„±ë©ë‹ˆë‹¤")
        
        logger.info(f"âœ… ë¦¬ë”ë³´ë“œ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: {len(leaderboard_data)}ê°œ í•­ëª©")
        return leaderboard_data
        
    except Exception as e:
        logger.error(f"âŒ ë¦¬ë”ë³´ë“œ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        logger.error(traceback.format_exc())
        return []

def upload_to_apps_script_web_app(data, mode='full'):  # ğŸ†• mode íŒŒë¼ë¯¸í„° ì¶”ê°€
    """ğŸš€ Apps Script Web Appìœ¼ë¡œ ë°ì´í„° ì „ì†¡ (JSON ì•ˆì „ ì²˜ë¦¬)"""
    logger.info("ğŸ“¤ Apps Script Web App ì—…ë¡œë“œ ì‹œì‘...")
    
    if not data:
        logger.error("âŒ ì—…ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        return False
    
    if not APPS_SCRIPT_WEB_APP_URL:
        logger.error("âŒ APPS_SCRIPT_WEB_APP_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        return save_to_github_pages(data)
    
    if SAFE_MODE:
        logger.info("ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œ: ê¸°ì¡´ 21ê°œ ì»¬ëŸ¼ë§Œ ì—…ë¡œë“œ")
    
    try:
        # ğŸ”§ ë°ì´í„° ì •ì œ ë° ì•ˆì „ ì²˜ë¦¬
        cleaned_data = clean_data_for_json(data)
        logger.info(f"ğŸ§¹ ë°ì´í„° ì •ì œ ì™„ë£Œ: {len(cleaned_data)}ê°œ í•­ëª©")
        
        # ğŸ†• ëª¨ë“œ ì •ë³´ í¬í•¨
        request_data = {
            'mode': mode,  # 'incremental' or 'full'
            'data': cleaned_data
        }
        
        # JSON ë°ì´í„° ì¤€ë¹„ (ì•ˆì „í•œ ì§ë ¬í™”)
        json_data = json.dumps(request_data, ensure_ascii=True, separators=(',', ':'))
        
        # ğŸ“Š ë°ì´í„° í¬ê¸° ì²´í¬
        data_size_mb = len(json_data.encode('utf-8')) / (1024 * 1024)
        logger.info(f"ğŸ“Š JSON í¬ê¸°: {data_size_mb:.2f}MB")
        
        # í¬ê¸°ê°€ ë„ˆë¬´ í¬ë©´ ì²­í¬ ë‹¨ìœ„ë¡œ ì „ì†¡
        if data_size_mb > 5:  # 5MB ì´ˆê³¼ì‹œ
            return upload_large_data_in_chunks(cleaned_data)
        
        headers = {
            'Content-Type': 'application/json; charset=utf-8',
            'User-Agent': 'STAKE-Leaderboard-GitHub-Action/1.0'
        }
        
        logger.info(f"ğŸ“¤ Apps Script Web Appìœ¼ë¡œ POST ìš”ì²­")
        logger.info(f"ğŸ“Š ë°ì´í„° í¬ê¸°: {len(cleaned_data)}ê°œ í•­ëª©, {data_size_mb:.2f}MB")
        
        response = requests.post(
            APPS_SCRIPT_WEB_APP_URL,
            data=json_data,
            headers=headers,
            timeout=300  # 5ë¶„ìœ¼ë¡œ ì¦ê°€
        )
        
        logger.info(f"ğŸ“¡ Apps Script ì‘ë‹µ: {response.status_code}")
        logger.info(f"ğŸ“„ ì‘ë‹µ ë‚´ìš©: {response.text[:500]}")
        
        if response.status_code == 200:
            try:
                result = response.json()
                if result.get('status') == 'success':
                    logger.info("âœ… Apps Script Web App ì—…ë¡œë“œ ì„±ê³µ!")
                    logger.info(f"ğŸ“Š ê¸°ë³¸ ì»¬ëŸ¼ ì—…ë°ì´íŠ¸: {result.get('basic_columns', 0)}ê°œ")
                    logger.info(f"ğŸ”§ í™•ì¥ ì»¬ëŸ¼ ì²˜ë¦¬: {result.get('enhanced_columns', 0)}ê°œ")
                    return True
                else:
                    logger.error(f"âŒ Apps Script ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('message', 'Unknown error')}")
                    return False
            except json.JSONDecodeError:
                logger.warning("âš ï¸ Apps Script ì‘ë‹µì´ JSONì´ ì•„ë‹˜ (í•˜ì§€ë§Œ 200 OK)")
                return True
        else:
            logger.error(f"âŒ Apps Script Web App ì—…ë¡œë“œ ì‹¤íŒ¨: {response.status_code}")
            logger.error(f"ğŸ“„ ì—ëŸ¬ ì‘ë‹µ: {response.text}")
            return False
        
    except requests.exceptions.Timeout:
        logger.error("â° Apps Script Web App ìš”ì²­ íƒ€ì„ì•„ì›ƒ (300ì´ˆ)")
        return False
    except Exception as e:
        logger.error(f"âŒ Apps Script Web App ì˜¤ë¥˜: {e}")
        return False

def clean_data_for_json(data):
    """ğŸ§¹ JSON ì•ˆì „ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë°ì´í„° ì •ì œ"""
    logger.info("ğŸ§¹ JSON ì•ˆì „ ì²˜ë¦¬ ì‹œì‘...")
    
    cleaned_data = []
    
    for item in data:
        cleaned_item = {}
        
        for key, value in item.items():
            # ğŸ”§ íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬
            if isinstance(value, str):
                # ë¬¸ì œê°€ ë  ìˆ˜ ìˆëŠ” ë¬¸ìë“¤ ì œê±°/êµì²´
                cleaned_value = value.replace('\n', ' ').replace('\r', ' ')
                cleaned_value = cleaned_value.replace('\t', ' ').replace('\\', '/')
                cleaned_value = cleaned_value.replace('"', "'").replace('\b', ' ')
                cleaned_value = cleaned_value.replace('\f', ' ').replace('\v', ' ')
                
                # ì œì–´ ë¬¸ì ì œê±°
                cleaned_value = ''.join(char for char in cleaned_value if ord(char) >= 32 or char in ['\n', '\r', '\t'])
                
                # ë„ˆë¬´ ê¸´ ë¬¸ìì—´ ìë¥´ê¸°
                if len(cleaned_value) > 1000:
                    cleaned_value = cleaned_value[:997] + "..."
                
                cleaned_item[key] = cleaned_value.strip()
                
            elif isinstance(value, (int, float)):
                # ìˆ«ìê°’ ì•ˆì „ ì²˜ë¦¬
                if isinstance(value, float):
                    if value != value:  # NaN ì²´í¬
                        cleaned_item[key] = 0
                    elif value == float('inf') or value == float('-inf'):
                        cleaned_item[key] = 0
                    else:
                        cleaned_item[key] = round(value, 6)
                else:
                    cleaned_item[key] = value
                    
            elif isinstance(value, bool):
                cleaned_item[key] = value
                
            elif value is None:
                cleaned_item[key] = ""
                
            else:
                # ê¸°íƒ€ íƒ€ì…ì€ ë¬¸ìì—´ë¡œ ë³€í™˜
                cleaned_item[key] = str(value)
        
        cleaned_data.append(cleaned_item)
    
    logger.info(f"âœ… ë°ì´í„° ì •ì œ ì™„ë£Œ: {len(cleaned_data)}ê°œ í•­ëª©")
    return cleaned_data

def upload_large_data_in_chunks(data):
    """ğŸ“¦ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²­í¬ ë‹¨ìœ„ ì—…ë¡œë“œ"""
    logger.info("ğŸ“¦ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²­í¬ ì—…ë¡œë“œ ì‹œì‘...")
    
    chunk_size = 100  # 100ê°œì”© ë‚˜ëˆ„ì–´ ì „ì†¡
    total_chunks = (len(data) + chunk_size - 1) // chunk_size
    
    try:
        for i in range(0, len(data), chunk_size):
            chunk = data[i:i + chunk_size]
            chunk_num = (i // chunk_size) + 1
            
            logger.info(f"ğŸ“¦ ì²­í¬ {chunk_num}/{total_chunks} ì—…ë¡œë“œ ì¤‘... ({len(chunk)}ê°œ í•­ëª©)")
            
            # ì²­í¬ ë°ì´í„° ì¤€ë¹„
            chunk_data = {
                "chunk_number": chunk_num,
                "total_chunks": total_chunks,
                "data": chunk,
                "is_chunk": True
            }
            
            json_data = json.dumps(chunk_data, ensure_ascii=True, separators=(',', ':'))
            
            headers = {
                'Content-Type': 'application/json; charset=utf-8',
                'User-Agent': 'STAKE-Leaderboard-GitHub-Action/1.0'
            }
            
            response = requests.post(
                APPS_SCRIPT_WEB_APP_URL,
                data=json_data,
                headers=headers,
                timeout=120
            )
            
            if response.status_code != 200:
                logger.error(f"âŒ ì²­í¬ {chunk_num} ì—…ë¡œë“œ ì‹¤íŒ¨: {response.status_code}")
                return False
            
            logger.info(f"âœ… ì²­í¬ {chunk_num}/{total_chunks} ì—…ë¡œë“œ ì™„ë£Œ")
            
            # ì²­í¬ ê°„ ëŒ€ê¸°
            time.sleep(1)
        
        logger.info("âœ… ëª¨ë“  ì²­í¬ ì—…ë¡œë“œ ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ì²­í¬ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def save_to_github_pages(data):
    """GitHub Pagesìš© JSON íŒŒì¼ ìƒì„± ë° ìë™ ì»¤ë°‹ (ë°±ì—…ìš©)"""
    logger.info("ğŸ“„ GitHub Pagesìš© JSON íŒŒì¼ ìƒì„±...")
    
    try:
        # public í´ë” ìƒì„±
        public_dir = '../public'
        os.makedirs(public_dir, exist_ok=True)
        
        # API í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ì •ë¦¬
        api_data = {
            "last_updated": datetime.now(timezone.utc).isoformat(),
            "total_wallets": len(data),
            "active_wallets": len([d for d in data if d.get('is_active')]),
            "phase": 1,
            "safe_mode": SAFE_MODE,
            "update_range": UPDATE_RANGE if SAFE_MODE else "A:AM",
            "leaderboard": data[:100]  # ìƒìœ„ 100ê°œ
        }
        
        # JSON íŒŒì¼ ì €ì¥
        json_file = f'{public_dir}/leaderboard.json'
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(api_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… JSON íŒŒì¼ ìƒì„±: {json_file}")
        logger.info(f"ğŸ“Š ë°ì´í„° í¬ê¸°: {len(api_data['leaderboard'])}ê°œ í•­ëª©")
        
        if SAFE_MODE:
            logger.info("ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œ: ì‹ ê·œ 18ê°œ ì»¬ëŸ¼ì€ Apps Scriptì—ì„œ ìë™ ì¶”ê°€ë©ë‹ˆë‹¤")
        
        # Git ìë™ ì»¤ë°‹ (GitHub Actions í™˜ê²½ì—ì„œ)
        try:
            import subprocess
            
            # Git ì„¤ì •
            subprocess.run(['git', 'config', 'user.name', 'STAKE-Bot'], 
                         cwd='..', check=False)
            subprocess.run(['git', 'config', 'user.email', 'stake-bot@noreply.github.com'], 
                         cwd='..', check=False)
            
            # íŒŒì¼ ì¶”ê°€ ë° ì»¤ë°‹
            subprocess.run(['git', 'add', 'public/leaderboard.json'], 
                         cwd='..', check=True)
            
            commit_msg = f"Update leaderboard data (Apps Script Web App) - {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M UTC')}"
            subprocess.run(['git', 'commit', '-m', commit_msg], 
                         cwd='..', check=True)
            
            subprocess.run(['git', 'push'], cwd='..', check=True)
            
            logger.info("âœ… GitHubì— ìë™ ì»¤ë°‹ ì™„ë£Œ")
            
        except subprocess.CalledProcessError as e:
            logger.warning(f"âš ï¸ Git ì»¤ë°‹ ì‹¤íŒ¨: {e}")
            logger.info("ğŸ“ íŒŒì¼ì€ ë¡œì»¬ì— ì €ì¥ë¨")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ GitHub Pages ìƒì„± ì‹¤íŒ¨: {e}")
        logger.error(traceback.format_exc())
        return False

def save_backup_data(data):
    """ë°±ì—… ë°ì´í„° ì €ì¥"""
    try:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        safe_mode_suffix = "_safe" if SAFE_MODE else ""
        backup_file = f'backup/stake_leaderboard_{timestamp}{safe_mode_suffix}.json'
        
        # ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs('backup', exist_ok=True)
        
        with open(backup_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ ë°±ì—… ì €ì¥ ì™„ë£Œ: {backup_file}")
        
        # CSVë„ ì €ì¥
        df = pd.DataFrame(data)
        csv_file = f'backup/stake_leaderboard_{timestamp}{safe_mode_suffix}.csv'
        df.to_csv(csv_file, index=False, encoding='utf-8-sig')
        logger.info(f"ğŸ’¾ CSV ë°±ì—… ì €ì¥ ì™„ë£Œ: {csv_file}")
        
    except Exception as e:
        logger.error(f"âŒ ë°±ì—… ì €ì¥ ì‹¤íŒ¨: {e}")

def update_leaderboard():
    """ì „ì²´ ë¦¬ë”ë³´ë“œ ì—…ë°ì´íŠ¸ í”„ë¡œì„¸ìŠ¤ (Apps Script Web App ì—°ë™)"""
    logger.info("ğŸ¯ === STAKE ë¦¬ë”ë³´ë“œ ì—…ë°ì´íŠ¸ ì‹œì‘ ===")
    
    if SAFE_MODE:
        logger.info("ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œ: ê¸°ì¡´ 21ê°œ ì»¬ëŸ¼ë§Œ ì—…ë°ì´íŠ¸")
        logger.info("ğŸ”’ ì‹ ê·œ 18ê°œ ì»¬ëŸ¼ ë³´í˜¸ (Apps Scriptì—ì„œ ìë™ ì²˜ë¦¬)")
    
    start_time = datetime.now()
    
    try:
        # 1. STAKE ë°ì´í„° ì¶”ì¶œ
        if not extract_all_stake_data():
            raise Exception("STAKE ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨")
        
        # 2. ë¦¬ë”ë³´ë“œ ë°ì´í„° ì²˜ë¦¬
        leaderboard_data = process_leaderboard_data()
        if not leaderboard_data:
            raise Exception("ë¦¬ë”ë³´ë“œ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨")
        
        # 3. ë°±ì—… ì €ì¥
        save_backup_data(leaderboard_data)
        
        # 4. ğŸš€ Apps Script Web App ì—…ë¡œë“œ (ì „ì²´ ëª¨ë“œ)
        if not upload_to_apps_script_web_app(leaderboard_data, mode='full'):
            logger.warning("âš ï¸ Apps Script Web App ì‹¤íŒ¨, GitHub Pagesë¡œ ì „í™˜...")
            if not save_to_github_pages(leaderboard_data):
                raise Exception("ëª¨ë“  ì—…ë¡œë“œ ë°©ë²• ì‹¤íŒ¨")
        
        # 5. ì„±ê³µ ë¡œê·¸
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        logger.info("ğŸ‰ === ë¦¬ë”ë³´ë“œ ì—…ë°ì´íŠ¸ ì™„ë£Œ ===")
        logger.info(f"â±ï¸ ì†Œìš” ì‹œê°„: {duration:.1f}ì´ˆ")
        logger.info(f"ğŸ“Š ì²˜ë¦¬ëœ í•­ëª©: {len(leaderboard_data)}ê°œ")
        logger.info(f"ğŸ“… ì™„ë£Œ ì‹œê°„: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        if SAFE_MODE:
            logger.info("ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œ ì™„ë£Œ: Apps Scriptê°€ ì‹ ê·œ ì»¬ëŸ¼ì„ ìë™ ê³„ì‚°í•©ë‹ˆë‹¤")
        
    except Exception as e:
        logger.error(f"ğŸ’¥ === ë¦¬ë”ë³´ë“œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ ===")
        logger.error(f"âŒ ì˜¤ë¥˜: {e}")
        logger.error(traceback.format_exc())

def start_scheduler():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
    logger.info("â° STAKE ë¦¬ë”ë³´ë“œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘")
    logger.info(f"ğŸ“‹ ì„¤ì •: 6ì‹œê°„ë§ˆë‹¤ ìë™ ì—…ë°ì´íŠ¸")
    logger.info(f"ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œ: {SAFE_MODE}")
    logger.info(f"ğŸš€ Apps Script Web App ì—°ë™")
    logger.info(f"ğŸ¯ ë‹¤ìŒ ì‹¤í–‰: {datetime.now() + pd.Timedelta(hours=6)}")
    
    # 6ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰
    schedule.every(6).hours.do(update_leaderboard)
    
    # ì¦‰ì‹œ í•œ ë²ˆ ì‹¤í–‰
    logger.info("ğŸš€ ì²« ë²ˆì§¸ ì—…ë°ì´íŠ¸ ì¦‰ì‹œ ì‹¤í–‰...")
    update_leaderboard()
    
    # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰
    while True:
        try:
            schedule.run_pending()
            time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬
        except KeyboardInterrupt:
            logger.info("â¹ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€ë¨")
            break
        except Exception as e:
            logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì˜¤ë¥˜: {e}")
            time.sleep(300)  # 5ë¶„ í›„ ì¬ì‹œë„

if __name__ == "__main__":
    import sys
    
    logger.info("ğŸ¥© STAKE ë¦¬ë”ë³´ë“œ ì‹œìŠ¤í…œ ì‹œì‘ (Apps Script Web App ì—°ë™)")
    logger.info(f"ğŸ”— RPC URL: {RPC_URL}")
    logger.info(f"ğŸ“‹ ìŠ¤í…Œì´í‚¹ ì»¨íŠ¸ë™íŠ¸: {STAKING_ADDRESS}")
    logger.info(f"ğŸ¯ ì œë„¤ì‹œìŠ¤ ë¸”ë¡: {GENESIS_BLOCK:,}")
    logger.info(f"ğŸ“Š í˜„ì¬ í˜ì´ì¦ˆ: {CURRENT_PHASE}/{TOTAL_PHASES}")
    logger.info(f"ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œ: {SAFE_MODE}")
    logger.info(f"ğŸš€ Apps Script Web App: {'ì„¤ì •ë¨' if APPS_SCRIPT_WEB_APP_URL else 'ë¯¸ì„¤ì •'}")
    
    try:
        # ì»¤ë§¨ë“œë¼ì¸ ì¸ì í™•ì¸
        if '--incremental' in sys.argv or os.environ.get('INCREMENTAL_MODE') == 'true':
            logger.info("ğŸ“ˆ === ì¦ë¶„ ì—…ë°ì´íŠ¸ ëª¨ë“œ ===")
            
            # 1. ì¦ë¶„ ë°ì´í„° ì¶”ì¶œ
            if not extract_incremental_stake_data():
                raise Exception("ì¦ë¶„ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨")
            
            # 2. ë¦¬ë”ë³´ë“œ ë°ì´í„° ì²˜ë¦¬
            leaderboard_data = process_leaderboard_data()
            if not leaderboard_data:
                raise Exception("ë¦¬ë”ë³´ë“œ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨")
            
            # 3. ë°±ì—… ì €ì¥
            save_backup_data(leaderboard_data)
            
            # 4. Apps Script Web App ì—…ë¡œë“œ
            if not upload_to_apps_script_web_app(leaderboard_data):
                logger.warning("âš ï¸ Apps Script Web App ì‹¤íŒ¨, GitHub Pagesë¡œ ì „í™˜...")
                if not save_to_github_pages(leaderboard_data):
                    raise Exception("ëª¨ë“  ì—…ë¡œë“œ ë°©ë²• ì‹¤íŒ¨")
            
            logger.info("âœ… ì¦ë¶„ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
        elif '--full-integrity' in sys.argv:
            logger.info("ğŸ” === ì „ì²´ ë¬´ê²°ì„± ê²€ì¦ ëª¨ë“œ ===")
            # ë‚˜ì¤‘ì— êµ¬í˜„
            logger.warning("âš ï¸ ì „ì²´ ë¬´ê²°ì„± ê²€ì¦ì€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
        else:
            logger.info("ğŸ”„ === ì „ì²´ ì—…ë°ì´íŠ¸ ëª¨ë“œ (ìŠ¤ì¼€ì¤„ëŸ¬) ===")
            start_scheduler()
            
    except Exception as e:
        logger.error(f"ğŸ’¥ ì‹œìŠ¤í…œ ì‹œì‘ ì‹¤íŒ¨: {e}")
        logger.error(traceback.format_exc())
        sys.exit(1)