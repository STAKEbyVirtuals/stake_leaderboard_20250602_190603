# === STAKE ë¦¬ë”ë³´ë“œ í†µí•© ì‹œìŠ¤í…œ ===
import requests
import pandas as pd
import json
import logging
import time
import schedule
from datetime import datetime, timezone
from collections import defaultdict
import traceback
import os

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('stake_leaderboard.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# === ì„¤ì • ===
RPC_URL = "https://mainnet.base.org"
STAKING_ADDRESS = "0xBa13ae24684bee910820Be1Fcf52067332F8412f"
TOKEN_ADDRESS = "0xA9C8bDDcb113068713193D030abB86C7e8D1F5bB"
STAKE_METHOD_ID = "0xa694fc3a"
UNSTAKE_METHOD_ID = "0xf48355b9"
GENESIS_BLOCK = 30732159

# Sheet.best API ì„¤ì • (GitHub Actions í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
SHEET_BEST_URL = os.environ.get('SHEET_BEST_URL')

if not SHEET_BEST_URL:
    # ë¡œì»¬ ê°œë°œ ì‹œ ê¸°ë³¸ê°’ (ì‹¤ì œ URLë¡œ êµì²´)
    SHEET_BEST_URL = 'https://api.sheetbest.com/sheets/de22dc8c-2579-461b-b255-4d9833d13dd3'
    logger.warning("âš ï¸ SHEET_BEST_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
else:
    logger.info(f"âœ… Sheet.best URL ì„¤ì • ì™„ë£Œ: {SHEET_BEST_URL[:30]}...")

# ë‚˜ë¨¸ì§€ ì½”ë“œëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€


# í˜ì´ì¦ˆ ì„¤ì •
CURRENT_PHASE = 1
TOTAL_PHASES = 6
TOTAL_SUPPLY = 1_000_000_000
AIRDROP_PERCENT = 0.25
PHASE_REWARD = (TOTAL_SUPPLY * AIRDROP_PERCENT) / TOTAL_PHASES

# ì „ì²´ ë°ì´í„° ì €ì¥ì†Œ
staking_data = defaultdict(lambda: {
    'total_staked': 0,
    'stake_count': 0,
    'unstake_count': 0,
    'unstake_attempts': [],
    'is_active': True,
    'first_stake_time': None,
    'last_action_time': None,
    'stake_transactions': [],
    'unstake_transactions': []
})

# stake_leaderboard_system.pyì— ì¶”ê°€í•  í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤:

def test_sheet_best_formats(data):
    """ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ Sheet.best API í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª Sheet.best API í˜•ì‹ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    if not SHEET_BEST_URL or 'YOUR_SHEET_ID' in SHEET_BEST_URL:
        logger.error("âŒ SHEET_BEST_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        return False
    
    # í…ŒìŠ¤íŠ¸í•  ë‹¤ì–‘í•œ í˜•ì‹ë“¤
    test_formats = []
    
    # í˜•ì‹ 1: ë§¤ìš° ê°„ë‹¨í•œ ê°ì²´
    test_formats.append({
        "name": "Simple Object",
        "data": {"address": "0x123", "rank": 1, "total": 1000}
    })
    
    # í˜•ì‹ 2: ë‹¨ìˆœ ë°°ì—´
    test_formats.append({
        "name": "Simple Array", 
        "data": [{"address": "0x123", "rank": 1}]
    })
    
    # í˜•ì‹ 3: ë¬¸ìì—´ë§Œ
    test_formats.append({
        "name": "String Only",
        "data": [{"address": "0x123", "rank": "1", "total": "1000"}]
    })
    
    # í˜•ì‹ 4: ì‹¤ì œ ë°ì´í„° 1ê°œ
    if data:
        sample = data[0]
        test_formats.append({
            "name": "Real Data Single",
            "data": [{
                "address": str(sample.get('address', '')),
                "rank": str(sample.get('rank', '')),
                "grade": str(sample.get('grade', '')),
                "total_staked": str(sample.get('total_staked', ''))
            }]
        })
    
    # í˜•ì‹ 5: ì»¬ëŸ¼ëª… ê°„ì†Œí™”
    test_formats.append({
        "name": "Short Columns",
        "data": [{"addr": "0x123", "rank": 1, "amount": 1000}]
    })
    
    # ê° í˜•ì‹ í…ŒìŠ¤íŠ¸
    for i, test_format in enumerate(test_formats, 1):
        logger.info(f"ğŸ“ í…ŒìŠ¤íŠ¸ {i}: {test_format['name']}")
        
        success = try_upload_format(test_format['data'], test_format['name'])
        
        if success:
            logger.info(f"âœ… ì„±ê³µ! í˜•ì‹: {test_format['name']}")
            return test_format['name']
        
        # ì ì‹œ ëŒ€ê¸° (API ì œí•œ ë°©ì§€)
        time.sleep(2)
    
    logger.error("âŒ ëª¨ë“  í˜•ì‹ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
    return False

def try_upload_format(test_data, format_name):
    """íŠ¹ì • í˜•ì‹ìœ¼ë¡œ ì—…ë¡œë“œ ì‹œë„"""
    try:
        headers = {
            'Content-Type': 'application/json',
            'User-Agent': 'STAKE-Test/1.0'
        }
        
        logger.info(f"ğŸ“¤ {format_name} í˜•ì‹ ì—…ë¡œë“œ ì‹œë„...")
        logger.info(f"ğŸ“Š ë°ì´í„°: {str(test_data)[:100]}...")
        
        response = requests.put(
            SHEET_BEST_URL,
            json=test_data,
            headers=headers,
            timeout=30
        )
        
        logger.info(f"ğŸ“¡ ì‘ë‹µ ì½”ë“œ: {response.status_code}")
        logger.info(f"ğŸ“„ ì‘ë‹µ ë‚´ìš©: {response.text[:200]}")
        
        if response.status_code == 200:
            return True
        else:
            return False
            
    except Exception as e:
        logger.error(f"âŒ {format_name} ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
        return False

def get_sheet_best_info():
    """Sheet.best API ì •ë³´ í™•ì¸"""
    logger.info("â„¹ï¸ Sheet.best API ì •ë³´ í™•ì¸...")
    
    try:
        # GET ìš”ì²­ìœ¼ë¡œ í˜„ì¬ ë°ì´í„° í™•ì¸
        response = requests.get(SHEET_BEST_URL, timeout=30)
        
        logger.info(f"ğŸ“¡ GET ì‘ë‹µ ì½”ë“œ: {response.status_code}")
        logger.info(f"ğŸ“„ í˜„ì¬ ì‹œíŠ¸ ë°ì´í„°: {response.text[:500]}")
        
        if response.status_code == 200:
            try:
                current_data = response.json()
                if current_data:
                    logger.info(f"ğŸ“Š í˜„ì¬ ë°ì´í„° êµ¬ì¡°: {type(current_data)}")
                    if isinstance(current_data, list) and len(current_data) > 0:
                        logger.info(f"ğŸ” ì²« ë²ˆì§¸ í•­ëª©: {current_data[0]}")
                        logger.info(f"ğŸ—ï¸ ì»¬ëŸ¼ëª…ë“¤: {list(current_data[0].keys()) if isinstance(current_data[0], dict) else 'Not dict'}")
            except:
                logger.info("ğŸ“„ JSON íŒŒì‹± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ ë°ì´í„°")
        
    except Exception as e:
        logger.error(f"âŒ Sheet.best ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}")


def rpc_call(method, params):
    """RPC í˜¸ì¶œ with ì—ëŸ¬ í•¸ë“¤ë§"""
    try:
        response = requests.post(RPC_URL, json={
            "jsonrpc": "2.0",
            "method": method,
            "params": params,
            "id": 1
        }, timeout=30)
        
        result = response.json()
        if 'error' in result:
            logger.error(f"RPC Error: {result['error']}")
            return None
        return result
    except Exception as e:
        logger.error(f"RPC í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return None

def get_latest_block():
    """ìµœì‹  ë¸”ë¡ ë²ˆí˜¸ ì¡°íšŒ"""
    result = rpc_call("eth_blockNumber", [])
    if result and 'result' in result:
        return int(result['result'], 16)
    return 0

def decode_amount(input_data):
    """ìŠ¤í…Œì´í‚¹ ìˆ˜ëŸ‰ ë””ì½”ë“œ"""
    try:
        if len(input_data) < 74:
            return 0
        amount_hex = input_data[10:74]
        return int(amount_hex, 16) / (10**18)
    except:
        return 0

def safe_scan_chunk(start_block, end_block, max_retries=3):
    """ì•ˆì „í•œ ì²­í¬ ìŠ¤ìº” with ì¬ì‹œë„"""
    chunk_size = end_block - start_block + 1
    
    # 1500ë¸”ë¡ ì´ˆê³¼í•˜ë©´ ë‚˜ëˆ„ê¸°
    if chunk_size > 1500:
        mid = start_block + 1499
        logs1 = safe_scan_chunk(start_block, mid, max_retries)
        logs2 = safe_scan_chunk(mid + 1, end_block, max_retries)
        return logs1 + logs2
    
    # ì¬ì‹œë„ ë¡œì§
    for attempt in range(max_retries):
        try:
            result = rpc_call("eth_getLogs", [{
                "fromBlock": hex(start_block),
                "toBlock": hex(end_block),
                "address": STAKING_ADDRESS
            }])
            
            if result and 'error' in result:
                if chunk_size > 1000:  # 1000ë¸”ë¡ìœ¼ë¡œ ì¬ì‹œë„
                    mid = start_block + 999
                    logs1 = safe_scan_chunk(start_block, mid, max_retries)
                    logs2 = safe_scan_chunk(mid + 1, end_block, max_retries)
                    return logs1 + logs2
                else:
                    logger.warning(f"ì²­í¬ ìŠ¤ìº” ì‹¤íŒ¨: {result['error']}")
                    return []
            
            elif result and 'result' in result:
                return result['result']
            else:
                logger.warning(f"ë¹ˆ ê²°ê³¼: ë¸”ë¡ {start_block}-{end_block}")
                return []
                
        except Exception as e:
            logger.error(f"ì²­í¬ ìŠ¤ìº” ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
            
    return []

def calculate_grade_percentile(data, genesis_deadline, all_active_wallets):
    """ë“±ê¸‰ ê³„ì‚° (í¼ì„¼íƒ€ì¼ ê¸°ì¤€)"""
    # Genesis: ì œë„¤ì‹œìŠ¤ ë¸”ë¡ ì´í›„ 1ì¼ ë‚´ ìŠ¤í…Œì´í‚¹ + ì–¸ìŠ¤í…Œì´í‚¹ ì‹œë„ ì—†ìŒ
    if (data['first_stake_time'] and 
        data['first_stake_time'] <= genesis_deadline and 
        data['is_active'] and 
        data['unstake_count'] == 0):
        return "Genesis OG", 0.0
    
    # ì–¸ìŠ¤í…Œì´í‚¹ ì‹œë„í•œ ê²½ìš°
    if not data['is_active']:
        return "Jeeted", 100.0
    
    # í™œì„± ì§€ê°‘ë“¤ì˜ íƒ€ì„ìŠ¤ì½”ì–´ ê¸°ì¤€ í¼ì„¼íƒ€ì¼ ê³„ì‚°
    current_time = int(datetime.now(timezone.utc).timestamp())
    holding_days = (current_time - data['first_stake_time']) / 86400 if data['first_stake_time'] else 0
    time_score = data['total_staked'] * holding_days
    
    # ëª¨ë“  í™œì„± ì§€ê°‘ì˜ íƒ€ì„ìŠ¤ì½”ì–´ ê³„ì‚°
    all_scores = []
    for _, wallet_data in all_active_wallets:
        if wallet_data['first_stake_time']:
            w_holding_days = (current_time - wallet_data['first_stake_time']) / 86400
            w_time_score = wallet_data['total_staked'] * w_holding_days
            all_scores.append(w_time_score)
    
    if not all_scores:
        return "Sizzlin' Noob", 100.0
    
    all_scores.sort(reverse=True)
    rank = len([s for s in all_scores if s > time_score]) + 1
    percentile = (rank / len(all_scores)) * 100
    
    # í¼ì„¼íƒ€ì¼ ê¸°ì¤€ ë“±ê¸‰
    if percentile <= 0.5:
        return "Smoke Flexer", percentile
    elif percentile <= 2:
        return "Steak Wizard", percentile
    elif percentile <= 5:
        return "Grilluminati", percentile
    elif percentile <= 15:
        return "Flame Juggler", percentile
    elif percentile <= 40:
        return "Flipstarter", percentile
    else:
        return "Sizzlin' Noob", percentile

def get_grade_emoji(grade):
    """ë“±ê¸‰ë³„ ì´ëª¨ì§€"""
    grade_emojis = {
        "Genesis OG": "ğŸŒŒ",
        "Smoke Flexer": "ğŸ”¥",
        "Steak Wizard": "ğŸ­",
        "Grilluminati": "ğŸ‘ï¸",
        "Flame Juggler": "ğŸ”¥",
        "Flipstarter": "ğŸ¥©",
        "Sizzlin' Noob": "ğŸ”°",
        "Jeeted": "ğŸ’€"
    }
    return grade_emojis.get(grade, "â“")

def extract_all_stake_data():
    """ì™„ì „í•œ STAKE ë°ì´í„° ì¶”ì¶œ"""
    logger.info("ğŸš€ ì „ì²´ STAKE ë°ì´í„° ì¶”ì¶œ ì‹œì‘...")
    
    try:
        latest_block = get_latest_block()
        if not latest_block:
            raise Exception("ìµœì‹  ë¸”ë¡ ì¡°íšŒ ì‹¤íŒ¨")
        
        total_blocks = latest_block - GENESIS_BLOCK
        logger.info(f"ğŸ“Š ìŠ¤ìº” ë²”ìœ„: {GENESIS_BLOCK:,} â†’ {latest_block:,} ({total_blocks:,}ë¸”ë¡)")
        
        # ì´ˆê¸°í™”
        staking_data.clear()
        
        total_stake_txs = 0
        total_unstake_txs = 0
        processed = 0
        
        current_block = GENESIS_BLOCK
        chunk_num = 1
        
        while current_block <= latest_block:
            chunk_end = min(current_block + 1499, latest_block)
            chunk_size = chunk_end - current_block + 1
            
            progress = processed / total_blocks * 100
            logger.info(f"ğŸ”„ {progress:.1f}% | ì²­í¬#{chunk_num} | ë¸”ë¡ {current_block:,}â†’{chunk_end:,}")
            
            logs = safe_scan_chunk(current_block, chunk_end)
            
            if not logs:
                current_block = chunk_end + 1
                processed += chunk_size
                chunk_num += 1
                continue
            
            # íŠ¸ëœì­ì…˜ ì²˜ë¦¬
            tx_hashes = list(set(log['transactionHash'] for log in logs))
            
            for tx_hash in tx_hashes:
                try:
                    tx_result = rpc_call("eth_getTransactionByHash", [tx_hash])
                    
                    if not tx_result or 'result' not in tx_result or not tx_result['result']:
                        continue
                    
                    tx = tx_result['result']
                    input_data = tx.get('input', '0x')
                    
                    if len(input_data) >= 10:
                        method_id = input_data[:10]
                        from_addr = tx['from'].lower()
                        block_num = int(tx['blockNumber'], 16)
                        
                        # ë¸”ë¡ íƒ€ì„ìŠ¤íƒ¬í”„
                        block_result = rpc_call("eth_getBlockByNumber", [tx['blockNumber'], False])
                        timestamp = 0
                        if block_result and 'result' in block_result and block_result['result']:
                            timestamp = int(block_result['result']['timestamp'], 16)
                        
                        if method_id == STAKE_METHOD_ID:
                            # ìŠ¤í…Œì´í‚¹ íŠ¸ëœì­ì…˜
                            amount = decode_amount(input_data)
                            
                            staking_data[from_addr]['total_staked'] += amount
                            staking_data[from_addr]['stake_count'] += 1
                            staking_data[from_addr]['is_active'] = True
                            
                            if not staking_data[from_addr]['first_stake_time']:
                                staking_data[from_addr]['first_stake_time'] = timestamp
                            
                            staking_data[from_addr]['last_action_time'] = timestamp
                            
                            staking_data[from_addr]['stake_transactions'].append({
                                'amount': amount,
                                'block': block_num,
                                'timestamp': timestamp,
                                'hash': tx_hash
                            })
                            
                            total_stake_txs += 1
                        
                        elif method_id == UNSTAKE_METHOD_ID:
                            # ì–¸ìŠ¤í…Œì´í‚¹ ì‹œë„
                            staking_data[from_addr]['unstake_count'] += 1
                            staking_data[from_addr]['is_active'] = False
                            staking_data[from_addr]['last_action_time'] = timestamp
                            
                            staking_data[from_addr]['unstake_attempts'].append({
                                'block': block_num,
                                'timestamp': timestamp,
                                'hash': tx_hash
                            })
                            
                            total_unstake_txs += 1
                
                except Exception as e:
                    continue
                    
                time.sleep(0.005)
            
            current_block = chunk_end + 1
            processed += chunk_size
            chunk_num += 1
            time.sleep(0.1)
        
        logger.info(f"ğŸ‰ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ!")
        logger.info(f"   ì´ Stake íŠ¸ëœì­ì…˜: {total_stake_txs:,}ê°œ")
        logger.info(f"   ì´ Unstake ì‹œë„: {total_unstake_txs:,}ê°œ")
        logger.info(f"   ì´ ì§€ê°‘ ìˆ˜: {len(staking_data):,}ê°œ")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        logger.error(traceback.format_exc())
        return False

def process_leaderboard_data():
    """ë¦¬ë”ë³´ë“œ ë°ì´í„° ì²˜ë¦¬ ë° ìƒì„±"""
    logger.info("ğŸ“Š ë¦¬ë”ë³´ë“œ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘...")
    
    try:
        # ì œë„¤ì‹œìŠ¤ ë¸”ë¡ íƒ€ì„ìŠ¤íƒ¬í”„ ê³„ì‚°
        block_result = rpc_call("eth_getBlockByNumber", [hex(GENESIS_BLOCK), False])
        genesis_timestamp = 0
        if block_result and 'result' in block_result and block_result['result']:
            genesis_timestamp = int(block_result['result']['timestamp'], 16)
        
        genesis_deadline = genesis_timestamp + 86400  # 1ì¼ í›„
        
        # í™œì„± ì§€ê°‘ë§Œ ì¶”ì¶œ
        all_wallets = [(addr, data) for addr, data in staking_data.items() if data['total_staked'] > 0]
        active_wallets = [(addr, data) for addr, data in all_wallets if data['is_active']]
        
        # íƒ€ì„ìŠ¤ì½”ì–´ ê¸°ì¤€ ì •ë ¬
        sorted_wallets = sorted(all_wallets, key=lambda x: (
            x[1]['total_staked'] * ((int(datetime.now(timezone.utc).timestamp()) - x[1]['first_stake_time']) / 86400)
            if x[1]['first_stake_time'] else 0
        ), reverse=True)
        
        leaderboard_data = []
        total_time_score = 0
        
        # ì „ì²´ íƒ€ì„ìŠ¤ì½”ì–´ ê³„ì‚° (ì—ì–´ë“œë ë¹„ìœ¨ ê³„ì‚°ìš©)
        current_time = int(datetime.now(timezone.utc).timestamp())
        for _, data in active_wallets:
            if data['first_stake_time']:
                holding_days = (current_time - data['first_stake_time']) / 86400
                total_time_score += data['total_staked'] * holding_days
        
        for rank, (address, data) in enumerate(sorted_wallets, 1):
            # ë“±ê¸‰ ë° í¼ì„¼íƒ€ì¼ ê³„ì‚°
            grade, percentile = calculate_grade_percentile(data, genesis_deadline, active_wallets)
            
            # íƒ€ì„ìŠ¤ì½”ì–´ ê³„ì‚°
            holding_days = 0
            time_score = 0
            if data['first_stake_time']:
                holding_days = (current_time - data['first_stake_time']) / 86400
                time_score = data['total_staked'] * holding_days
            
            # ì—ì–´ë“œë í• ë‹¹ ë¹„ìœ¨ ê³„ì‚°
            airdrop_share_phase = 0
            airdrop_share_total = 0
            if data['is_active'] and total_time_score > 0:
                airdrop_share_phase = (time_score / total_time_score) * 100
                airdrop_share_total = airdrop_share_phase * TOTAL_PHASES
            
            # 24ì‹œê°„ ë³€ë™ (ì„ì‹œë¡œ 0 ì„¤ì •, í–¥í›„ ì´ì „ ë°ì´í„°ì™€ ë¹„êµ)
            rank_change_24h = 0
            score_change_24h = 0
            
            leaderboard_data.append({
                'address': address,
                'rank': rank,
                'grade': grade,
                'grade_emoji': get_grade_emoji(grade),
                'percentile': round(percentile, 2),
                'total_staked': round(data['total_staked'], 4),
                'time_score': round(time_score, 2),
                'holding_days': round(holding_days, 1),
                'stake_count': data['stake_count'],
                'unstake_count': data['unstake_count'],
                'is_active': data['is_active'],
                'current_phase': CURRENT_PHASE,
                'phase_score': round(time_score, 2),  # í˜„ì¬ëŠ” ë™ì¼, í–¥í›„ í˜ì´ì¦ˆë³„ ë¡œì§ ì¶”ê°€
                'total_score_all_phases': round(time_score, 2),
                'airdrop_share_phase': round(airdrop_share_phase, 6),
                'airdrop_share_total': round(airdrop_share_total, 6),
                'first_stake_time': data['first_stake_time'],
                'last_action_time': data['last_action_time'],
                'rank_change_24h': rank_change_24h,
                'score_change_24h': score_change_24h,
                'phase_rank_history': f"P1:{rank}"  # í–¥í›„ í™•ì¥
            })
        
        logger.info(f"âœ… ë¦¬ë”ë³´ë“œ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: {len(leaderboard_data)}ê°œ í•­ëª©")
        return leaderboard_data
        
    except Exception as e:
        logger.error(f"âŒ ë¦¬ë”ë³´ë“œ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        logger.error(traceback.format_exc())
        return []

# stake_leaderboard_system.py íŒŒì¼ì˜ upload_to_sheet_best í•¨ìˆ˜ë¥¼ ì´ë ‡ê²Œ ìˆ˜ì •:

# ê¸°ì¡´ upload_to_sheet_best í•¨ìˆ˜ë¥¼ ì´ë ‡ê²Œ ìˆ˜ì •:
def upload_to_sheet_best(data):
    """Sheet.best API ì—…ë¡œë“œ (í˜•ì‹ í…ŒìŠ¤íŠ¸ í¬í•¨)"""
    logger.info("ğŸ“¤ Sheet.best API ì—…ë¡œë“œ ì‹œì‘...")
    
    if not data:
        logger.error("âŒ ì—…ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        return False
    
    # 1. í˜„ì¬ ì‹œíŠ¸ ì •ë³´ í™•ì¸
    get_sheet_best_info()
    
    # 2. ë‹¤ì–‘í•œ í˜•ì‹ í…ŒìŠ¤íŠ¸
    successful_format = test_sheet_best_formats(data)
    
    if successful_format:
        logger.info(f"ğŸ¯ ì„±ê³µí•œ í˜•ì‹ ë°œê²¬: {successful_format}")
        
        # 3. ì„±ê³µí•œ í˜•ì‹ìœ¼ë¡œ ì „ì²´ ë°ì´í„° ì—…ë¡œë“œ
        if successful_format == "Simple Array":
            final_data = []
            for item in data[:50]:  # 50ê°œê¹Œì§€
                final_data.append({
                    "address": str(item.get('address', '')),
                    "rank": int(item.get('rank', 0))
                })
        
        elif successful_format == "String Only":
            final_data = []
            for item in data[:50]:
                final_data.append({
                    "address": str(item.get('address', '')),
                    "rank": str(item.get('rank', '')),
                    "grade": str(item.get('grade', '')),
                    "total_staked": str(item.get('total_staked', ''))
                })
        
        else:
            # ê¸°ë³¸ í˜•ì‹
            final_data = data[:50]
        
        # ìµœì¢… ì—…ë¡œë“œ
        return try_upload_format(final_data, "Final Upload")
    
    else:
        logger.error("âŒ ëª¨ë“  í˜•ì‹ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return False

# ì¶”ê°€: math ëª¨ë“ˆ import í•„ìš”
import math

def save_backup_data(data):
    """ë°±ì—… ë°ì´í„° ì €ì¥"""
    try:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_file = f'backup/stake_leaderboard_{timestamp}.json'
        
        # ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs('backup', exist_ok=True)
        
        with open(backup_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ ë°±ì—… ì €ì¥ ì™„ë£Œ: {backup_file}")
        
        # CSVë„ ì €ì¥
        df = pd.DataFrame(data)
        csv_file = f'backup/stake_leaderboard_{timestamp}.csv'
        df.to_csv(csv_file, index=False, encoding='utf-8-sig')
        logger.info(f"ğŸ’¾ CSV ë°±ì—… ì €ì¥ ì™„ë£Œ: {csv_file}")
        
    except Exception as e:
        logger.error(f"âŒ ë°±ì—… ì €ì¥ ì‹¤íŒ¨: {e}")

def update_leaderboard():
    """ì „ì²´ ë¦¬ë”ë³´ë“œ ì—…ë°ì´íŠ¸ í”„ë¡œì„¸ìŠ¤"""
    logger.info("ğŸ¯ === STAKE ë¦¬ë”ë³´ë“œ ì—…ë°ì´íŠ¸ ì‹œì‘ ===")
    start_time = datetime.now()
    
    try:
        # 1. STAKE ë°ì´í„° ì¶”ì¶œ
        if not extract_all_stake_data():
            raise Exception("STAKE ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨")
        
        # 2. ë¦¬ë”ë³´ë“œ ë°ì´í„° ì²˜ë¦¬
        leaderboard_data = process_leaderboard_data()
        if not leaderboard_data:
            raise Exception("ë¦¬ë”ë³´ë“œ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨")
        
        # 3. ë°±ì—… ì €ì¥
        save_backup_data(leaderboard_data)
        
        # 4. Sheet.best ì—…ë¡œë“œ
        if not upload_to_sheet_best(leaderboard_data):
            raise Exception("Sheet.best ì—…ë¡œë“œ ì‹¤íŒ¨")
        
        # 5. ì„±ê³µ ë¡œê·¸
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        logger.info("ğŸ‰ === ë¦¬ë”ë³´ë“œ ì—…ë°ì´íŠ¸ ì™„ë£Œ ===")
        logger.info(f"â±ï¸ ì†Œìš” ì‹œê°„: {duration:.1f}ì´ˆ")
        logger.info(f"ğŸ“Š ì²˜ë¦¬ëœ í•­ëª©: {len(leaderboard_data)}ê°œ")
        logger.info(f"ğŸ“… ì™„ë£Œ ì‹œê°„: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
    except Exception as e:
        logger.error(f"ğŸ’¥ === ë¦¬ë”ë³´ë“œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ ===")
        logger.error(f"âŒ ì˜¤ë¥˜: {e}")
        logger.error(traceback.format_exc())

def start_scheduler():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
    logger.info("â° STAKE ë¦¬ë”ë³´ë“œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘")
    logger.info(f"ğŸ“‹ ì„¤ì •: 6ì‹œê°„ë§ˆë‹¤ ìë™ ì—…ë°ì´íŠ¸")
    logger.info(f"ğŸ¯ ë‹¤ìŒ ì‹¤í–‰: {datetime.now() + pd.Timedelta(hours=6)}")
    
    # 6ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰
    schedule.every(6).hours.do(update_leaderboard)
    
    # ì¦‰ì‹œ í•œ ë²ˆ ì‹¤í–‰
    logger.info("ğŸš€ ì²« ë²ˆì§¸ ì—…ë°ì´íŠ¸ ì¦‰ì‹œ ì‹¤í–‰...")
    update_leaderboard()
    
    # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰
    while True:
        try:
            schedule.run_pending()
            time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬
        except KeyboardInterrupt:
            logger.info("â¹ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€ë¨")
            break
        except Exception as e:
            logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì˜¤ë¥˜: {e}")
            time.sleep(300)  # 5ë¶„ í›„ ì¬ì‹œë„

if __name__ == "__main__":
    logger.info("ğŸ¥© STAKE ë¦¬ë”ë³´ë“œ ì‹œìŠ¤í…œ ì‹œì‘")
    logger.info(f"ğŸ”— RPC URL: {RPC_URL}")
    logger.info(f"ğŸ“‹ ìŠ¤í…Œì´í‚¹ ì»¨íŠ¸ë™íŠ¸: {STAKING_ADDRESS}")
    logger.info(f"ğŸ¯ ì œë„¤ì‹œìŠ¤ ë¸”ë¡: {GENESIS_BLOCK:,}")
    logger.info(f"ğŸ“Š í˜„ì¬ í˜ì´ì¦ˆ: {CURRENT_PHASE}/{TOTAL_PHASES}")
    
    try:
        start_scheduler()
    except Exception as e:
        logger.error(f"ğŸ’¥ ì‹œìŠ¤í…œ ì‹œì‘ ì‹¤íŒ¨: {e}")
        logger.error(traceback.format_exc())